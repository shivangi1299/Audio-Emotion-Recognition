{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741878</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>17.240803</td>\n",
       "      <td>5.452007</td>\n",
       "      <td>-0.011167</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.01226</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730280</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>17.609236</td>\n",
       "      <td>5.065307</td>\n",
       "      <td>-0.011026</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2         3         4          5         6         7         8   \\\n",
       "0   1   1   1  0.741878  0.033103  17.240803  5.452007 -0.011167  0.025178   \n",
       "1   1   1   1  0.730280  0.029398  17.609236  5.065307 -0.011026  0.024742   \n",
       "\n",
       "         9        10        11        12        13        14        15  \\\n",
       "0  0.016555  0.01226  0.004946  0.009310  0.001166  0.001056  0.000304   \n",
       "1  0.019960  0.01631  0.005169  0.007958  0.001348  0.001372  0.000193   \n",
       "\n",
       "         16  \n",
       "0  0.000295  \n",
       "1  0.000144  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "dataset = pd.read_csv('C:/Users/SHIVANGI GUPTA/Documents/College PDFs/Sem-V/Elective 2- Data Analytics/details.csv', header=None)\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.651485</td>\n",
       "      <td>0.042916</td>\n",
       "      <td>18.648201</td>\n",
       "      <td>4.623741</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.016919</td>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.542544</td>\n",
       "      <td>0.652432</td>\n",
       "      <td>0.205126</td>\n",
       "      <td>0.261808</td>\n",
       "      <td>0.038610</td>\n",
       "      <td>0.036167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.175356</td>\n",
       "      <td>0.499061</td>\n",
       "      <td>0.500174</td>\n",
       "      <td>0.068892</td>\n",
       "      <td>0.016321</td>\n",
       "      <td>0.966975</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.846848</td>\n",
       "      <td>1.595897</td>\n",
       "      <td>1.759491</td>\n",
       "      <td>2.515182</td>\n",
       "      <td>0.792666</td>\n",
       "      <td>1.222381</td>\n",
       "      <td>0.137835</td>\n",
       "      <td>0.146518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451768</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>15.527443</td>\n",
       "      <td>3.046966</td>\n",
       "      <td>-0.021561</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608887</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>17.972610</td>\n",
       "      <td>4.293062</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>0.021871</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.664519</td>\n",
       "      <td>0.040745</td>\n",
       "      <td>18.619720</td>\n",
       "      <td>4.679566</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>0.045330</td>\n",
       "      <td>0.045931</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704543</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>19.238081</td>\n",
       "      <td>4.990831</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.211921</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>0.221398</td>\n",
       "      <td>0.228964</td>\n",
       "      <td>0.055196</td>\n",
       "      <td>0.055404</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0.008517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785410</td>\n",
       "      <td>0.130125</td>\n",
       "      <td>21.914929</td>\n",
       "      <td>5.981041</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>16.809935</td>\n",
       "      <td>37.530891</td>\n",
       "      <td>25.389278</td>\n",
       "      <td>40.882316</td>\n",
       "      <td>14.219903</td>\n",
       "      <td>20.427559</td>\n",
       "      <td>1.831944</td>\n",
       "      <td>2.072301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1440.000000  1440.000000  1440.000000  1440.000000  1440.000000   \n",
       "mean      4.733333     1.466667     0.500000     0.651485     0.042916   \n",
       "std       2.175356     0.499061     0.500174     0.068892     0.016321   \n",
       "min       1.000000     1.000000     0.000000     0.451768     0.010507   \n",
       "25%       3.000000     1.000000     0.000000     0.608887     0.031593   \n",
       "50%       5.000000     1.000000     0.500000     0.664519     0.040745   \n",
       "75%       7.000000     2.000000     1.000000     0.704543     0.050701   \n",
       "max       8.000000     2.000000     1.000000     0.785410     0.130125   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1440.000000  1440.000000  1440.000000  1440.000000  1440.000000   \n",
       "mean     18.648201     4.623741     0.000713     0.016919     0.282462   \n",
       "std       0.966975     0.516899     0.007195     0.007731     0.846848   \n",
       "min      15.527443     3.046966    -0.021561     0.002932     0.000533   \n",
       "25%      17.972610     4.293062    -0.004221     0.011469     0.020353   \n",
       "50%      18.619720     4.679566     0.000753     0.015737     0.064134   \n",
       "75%      19.238081     4.990831     0.005195     0.021057     0.211921   \n",
       "max      21.914929     5.981041     0.027705     0.055035    16.809935   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  1440.000000  1440.000000  1440.000000  1440.000000  1440.000000   \n",
       "mean      0.418446     0.542544     0.652432     0.205126     0.261808   \n",
       "std       1.595897     1.759491     2.515182     0.792666     1.222381   \n",
       "min       0.000328     0.000019     0.000024     0.000004     0.000003   \n",
       "25%       0.021871     0.009036     0.009802     0.001616     0.001639   \n",
       "50%       0.070562     0.045330     0.045931     0.009216     0.009043   \n",
       "75%       0.287687     0.221398     0.228964     0.055196     0.055404   \n",
       "max      37.530891    25.389278    40.882316    14.219903    20.427559   \n",
       "\n",
       "                15           16  \n",
       "count  1440.000000  1440.000000  \n",
       "mean      0.038610     0.036167  \n",
       "std       0.137835     0.146518  \n",
       "min       0.000002     0.000002  \n",
       "25%       0.000252     0.000186  \n",
       "50%       0.001617     0.001321  \n",
       "75%       0.011045     0.008517  \n",
       "max       1.831944     2.072301  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input features and target variables\n",
    "X= dataset.iloc[:,3:17]\n",
    "y= dataset.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.741878</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>17.240803</td>\n",
       "      <td>5.452007</td>\n",
       "      <td>-0.011167</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.01226</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730280</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>17.609236</td>\n",
       "      <td>5.065307</td>\n",
       "      <td>-0.011026</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         3         4          5         6         7         8         9   \\\n",
       "0  0.741878  0.033103  17.240803  5.452007 -0.011167  0.025178  0.016555   \n",
       "1  0.730280  0.029398  17.609236  5.065307 -0.011026  0.024742  0.019960   \n",
       "\n",
       "        10        11        12        13        14        15        16  \n",
       "0  0.01226  0.004946  0.009310  0.001166  0.001056  0.000304  0.000295  \n",
       "1  0.01631  0.005169  0.007958  0.001348  0.001372  0.000193  0.000144  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31254565, -0.60150695, -1.45596933, ..., -0.21338849,\n",
       "        -0.27800729, -0.24491821],\n",
       "       [ 1.144144  , -0.8285502 , -1.07482106, ..., -0.21312999,\n",
       "        -0.27881247, -0.24594868],\n",
       "       [ 1.35122488, -0.04803802, -1.31853595, ..., -0.21047183,\n",
       "        -0.27882972, -0.24590668],\n",
       "       ...,\n",
       "       [-1.12550855,  0.15616116, -0.41793984, ..., -0.16667768,\n",
       "        -0.19226861, -0.18148795],\n",
       "       [-0.72238082, -0.95896952, -0.22015519, ..., -0.14462369,\n",
       "        -0.20029241, -0.20758588],\n",
       "       [-0.28661147,  0.14645661, -0.37628502, ..., -0.0747627 ,\n",
       "        -0.25255224, -0.22320433]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(7, activation='relu', kernel_initializer='random_normal', input_dim=14))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(7, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1008/1008 [==============================] - 0s 99us/step - loss: -303480.7792 - accuracy: 0.0635\n",
      "Epoch 2/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -310982.0085 - accuracy: 0.0635\n",
      "Epoch 3/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -318590.8501 - accuracy: 0.0635\n",
      "Epoch 4/100\n",
      "1008/1008 [==============================] - 0s 89us/step - loss: -326335.4713 - accuracy: 0.0635\n",
      "Epoch 5/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -334172.7930 - accuracy: 0.0635\n",
      "Epoch 6/100\n",
      "1008/1008 [==============================] - 0s 92us/step - loss: -342136.7734 - accuracy: 0.0635\n",
      "Epoch 7/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -350230.4909 - accuracy: 0.0635\n",
      "Epoch 8/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -358408.3796 - accuracy: 0.0635\n",
      "Epoch 9/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -366724.0308 - accuracy: 0.0635\n",
      "Epoch 10/100\n",
      "1008/1008 [==============================] - 0s 88us/step - loss: -375139.5929 - accuracy: 0.0635\n",
      "Epoch 11/100\n",
      "1008/1008 [==============================] - 0s 90us/step - loss: -383680.9966 - accuracy: 0.0635\n",
      "Epoch 12/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -392365.2770 - accuracy: 0.0635\n",
      "Epoch 13/100\n",
      "1008/1008 [==============================] - 0s 110us/step - loss: -401154.1376 - accuracy: 0.0635\n",
      "Epoch 14/100\n",
      "1008/1008 [==============================] - 0s 116us/step - loss: -410082.4816 - accuracy: 0.0635\n",
      "Epoch 15/100\n",
      "1008/1008 [==============================] - 0s 113us/step - loss: -419127.1878 - accuracy: 0.0635\n",
      "Epoch 16/100\n",
      "1008/1008 [==============================] - 0s 140us/step - loss: -428274.0821 - accuracy: 0.0635\n",
      "Epoch 17/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -437547.9976 - accuracy: 0.0635\n",
      "Epoch 18/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -446943.0200 - accuracy: 0.0635\n",
      "Epoch 19/100\n",
      "1008/1008 [==============================] - 0s 88us/step - loss: -456474.1474 - accuracy: 0.0635\n",
      "Epoch 20/100\n",
      "1008/1008 [==============================] - 0s 110us/step - loss: -466128.2011 - accuracy: 0.0635\n",
      "Epoch 21/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -475892.6126 - accuracy: 0.0635\n",
      "Epoch 22/100\n",
      "1008/1008 [==============================] - 0s 89us/step - loss: -485803.7869 - accuracy: 0.0635\n",
      "Epoch 23/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -495811.4856 - accuracy: 0.0635\n",
      "Epoch 24/100\n",
      "1008/1008 [==============================] - 0s 97us/step - loss: -505929.0958 - accuracy: 0.0635\n",
      "Epoch 25/100\n",
      "1008/1008 [==============================] - 0s 110us/step - loss: -516169.1594 - accuracy: 0.0635\n",
      "Epoch 26/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -526549.7062 - accuracy: 0.0635\n",
      "Epoch 27/100\n",
      "1008/1008 [==============================] - 0s 91us/step - loss: -537056.2831 - accuracy: 0.0635\n",
      "Epoch 28/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -547713.6859 - accuracy: 0.0635\n",
      "Epoch 29/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -558500.3656 - accuracy: 0.0635\n",
      "Epoch 30/100\n",
      "1008/1008 [==============================] - 0s 100us/step - loss: -569391.1069 - accuracy: 0.0635\n",
      "Epoch 31/100\n",
      "1008/1008 [==============================] - 0s 114us/step - loss: -580445.3770 - accuracy: 0.0635\n",
      "Epoch 32/100\n",
      "1008/1008 [==============================] - 0s 119us/step - loss: -591633.9191 - accuracy: 0.0635\n",
      "Epoch 33/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -602949.7343 - accuracy: 0.0635\n",
      "Epoch 34/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -614397.7636 - accuracy: 0.0635\n",
      "Epoch 35/100\n",
      "1008/1008 [==============================] - 0s 108us/step - loss: -625995.9101 - accuracy: 0.0635\n",
      "Epoch 36/100\n",
      "1008/1008 [==============================] - 0s 115us/step - loss: -637708.1490 - accuracy: 0.0635\n",
      "Epoch 37/100\n",
      "1008/1008 [==============================] - 0s 136us/step - loss: -649555.1187 - accuracy: 0.0635\n",
      "Epoch 38/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -661588.6669 - accuracy: 0.0635\n",
      "Epoch 39/100\n",
      "1008/1008 [==============================] - 0s 90us/step - loss: -673699.3594 - accuracy: 0.0635\n",
      "Epoch 40/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -686012.9785 - accuracy: 0.0635\n",
      "Epoch 41/100\n",
      "1008/1008 [==============================] - 0s 92us/step - loss: -698449.2958 - accuracy: 0.0635\n",
      "Epoch 42/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -711020.3783 - accuracy: 0.0635\n",
      "Epoch 43/100\n",
      "1008/1008 [==============================] - 0s 87us/step - loss: -723728.2135 - accuracy: 0.0635\n",
      "Epoch 44/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -736578.4395 - accuracy: 0.0635\n",
      "Epoch 45/100\n",
      "1008/1008 [==============================] - 0s 138us/step - loss: -749576.5663 - accuracy: 0.0635\n",
      "Epoch 46/100\n",
      "1008/1008 [==============================] - 0s 120us/step - loss: -762722.4754 - accuracy: 0.0635\n",
      "Epoch 47/100\n",
      "1008/1008 [==============================] - 0s 116us/step - loss: -775999.0457 - accuracy: 0.0635\n",
      "Epoch 48/100\n",
      "1008/1008 [==============================] - 0s 115us/step - loss: -789427.1929 - accuracy: 0.0635\n",
      "Epoch 49/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -802996.5518 - accuracy: 0.0635\n",
      "Epoch 50/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -816729.7277 - accuracy: 0.0635\n",
      "Epoch 51/100\n",
      "1008/1008 [==============================] - 0s 139us/step - loss: -830597.7146 - accuracy: 0.0635\n",
      "Epoch 52/100\n",
      "1008/1008 [==============================] - 0s 111us/step - loss: -844605.2426 - accuracy: 0.0635\n",
      "Epoch 53/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -858767.6833 - accuracy: 0.0635\n",
      "Epoch 54/100\n",
      "1008/1008 [==============================] - 0s 92us/step - loss: -873083.5786 - accuracy: 0.0635\n",
      "Epoch 55/100\n",
      "1008/1008 [==============================] - 0s 90us/step - loss: -887580.4731 - accuracy: 0.0635\n",
      "Epoch 56/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -902192.8362 - accuracy: 0.0635\n",
      "Epoch 57/100\n",
      "1008/1008 [==============================] - 0s 88us/step - loss: -916970.1055 - accuracy: 0.0635\n",
      "Epoch 58/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -931894.6440 - accuracy: 0.0635\n",
      "Epoch 59/100\n",
      "1008/1008 [==============================] - 0s 92us/step - loss: -946980.2611 - accuracy: 0.0635\n",
      "Epoch 60/100\n",
      "1008/1008 [==============================] - 0s 98us/step - loss: -962171.2214 - accuracy: 0.0635\n",
      "Epoch 61/100\n",
      "1008/1008 [==============================] - 0s 91us/step - loss: -977544.7502 - accuracy: 0.0635\n",
      "Epoch 62/100\n",
      "1008/1008 [==============================] - 0s 88us/step - loss: -993007.8146 - accuracy: 0.0635\n",
      "Epoch 63/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -1008678.9812 - accuracy: 0.0635\n",
      "Epoch 64/100\n",
      "1008/1008 [==============================] - 0s 87us/step - loss: -1024467.2453 - accuracy: 0.0635\n",
      "Epoch 65/100\n",
      "1008/1008 [==============================] - 0s 106us/step - loss: -1040430.2909 - accuracy: 0.0635\n",
      "Epoch 66/100\n",
      "1008/1008 [==============================] - 0s 89us/step - loss: -1056508.7215 - accuracy: 0.0635\n",
      "Epoch 67/100\n",
      "1008/1008 [==============================] - 0s 89us/step - loss: -1072804.4620 - accuracy: 0.0635\n",
      "Epoch 68/100\n",
      "1008/1008 [==============================] - 0s 90us/step - loss: -1089188.7972 - accuracy: 0.0635\n",
      "Epoch 69/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -1105801.2793 - accuracy: 0.0635\n",
      "Epoch 70/100\n",
      "1008/1008 [==============================] - 0s 97us/step - loss: -1122563.5180 - accuracy: 0.0635\n",
      "Epoch 71/100\n",
      "1008/1008 [==============================] - 0s 101us/step - loss: -1139473.9466 - accuracy: 0.0635\n",
      "Epoch 72/100\n",
      "1008/1008 [==============================] - 0s 89us/step - loss: -1156540.6899 - accuracy: 0.0635\n",
      "Epoch 73/100\n",
      "1008/1008 [==============================] - 0s 91us/step - loss: -1173777.4335 - accuracy: 0.0635\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 0s 107us/step - loss: -1191123.0518 - accuracy: 0.0635\n",
      "Epoch 75/100\n",
      "1008/1008 [==============================] - 0s 111us/step - loss: -1208679.7228 - accuracy: 0.0635\n",
      "Epoch 76/100\n",
      "1008/1008 [==============================] - 0s 97us/step - loss: -1226392.0865 - accuracy: 0.0635\n",
      "Epoch 77/100\n",
      "1008/1008 [==============================] - 0s 102us/step - loss: -1244254.6683 - accuracy: 0.0635\n",
      "Epoch 78/100\n",
      "1008/1008 [==============================] - 0s 99us/step - loss: -1262345.0883 - accuracy: 0.0635\n",
      "Epoch 79/100\n",
      "1008/1008 [==============================] - 0s 102us/step - loss: -1280571.1517 - accuracy: 0.0635\n",
      "Epoch 80/100\n",
      "1008/1008 [==============================] - 0s 98us/step - loss: -1299018.8421 - accuracy: 0.0635\n",
      "Epoch 81/100\n",
      "1008/1008 [==============================] - 0s 102us/step - loss: -1317564.0098 - accuracy: 0.0635\n",
      "Epoch 82/100\n",
      "1008/1008 [==============================] - 0s 103us/step - loss: -1336355.0161 - accuracy: 0.0635\n",
      "Epoch 83/100\n",
      "1008/1008 [==============================] - 0s 101us/step - loss: -1355278.3830 - accuracy: 0.0635\n",
      "Epoch 84/100\n",
      "1008/1008 [==============================] - 0s 106us/step - loss: -1374316.6223 - accuracy: 0.0635\n",
      "Epoch 85/100\n",
      "1008/1008 [==============================] - 0s 112us/step - loss: -1393574.2315 - accuracy: 0.0635\n",
      "Epoch 86/100\n",
      "1008/1008 [==============================] - 0s 108us/step - loss: -1412990.4122 - accuracy: 0.0635\n",
      "Epoch 87/100\n",
      "1008/1008 [==============================] - 0s 91us/step - loss: -1432570.1993 - accuracy: 0.0635\n",
      "Epoch 88/100\n",
      "1008/1008 [==============================] - 0s 93us/step - loss: -1452356.0636 - accuracy: 0.0635\n",
      "Epoch 89/100\n",
      "1008/1008 [==============================] - 0s 95us/step - loss: -1472273.3535 - accuracy: 0.0635\n",
      "Epoch 90/100\n",
      "1008/1008 [==============================] - 0s 101us/step - loss: -1492356.9125 - accuracy: 0.0635\n",
      "Epoch 91/100\n",
      "1008/1008 [==============================] - 0s 117us/step - loss: -1512667.2248 - accuracy: 0.0635\n",
      "Epoch 92/100\n",
      "1008/1008 [==============================] - 0s 113us/step - loss: -1533083.2407 - accuracy: 0.0635\n",
      "Epoch 93/100\n",
      "1008/1008 [==============================] - 0s 94us/step - loss: -1553694.5816 - accuracy: 0.0635\n",
      "Epoch 94/100\n",
      "1008/1008 [==============================] - 0s 103us/step - loss: -1574512.5038 - accuracy: 0.0635\n",
      "Epoch 95/100\n",
      "1008/1008 [==============================] - 0s 101us/step - loss: -1595429.0157 - accuracy: 0.0635\n",
      "Epoch 96/100\n",
      "1008/1008 [==============================] - 0s 125us/step - loss: -1616618.3998 - accuracy: 0.0635\n",
      "Epoch 97/100\n",
      "1008/1008 [==============================] - 0s 122us/step - loss: -1637970.8426 - accuracy: 0.0635\n",
      "Epoch 98/100\n",
      "1008/1008 [==============================] - 0s 100us/step - loss: -1659453.4994 - accuracy: 0.0635\n",
      "Epoch 99/100\n",
      "1008/1008 [==============================] - 0s 114us/step - loss: -1681152.1765 - accuracy: 0.0635\n",
      "Epoch 100/100\n",
      "1008/1008 [==============================] - 0s 123us/step - loss: -1703065.8030 - accuracy: 0.0635\n",
      "432/432 [==============================] - 0s 55us/step\n",
      "\n",
      "accuracy: 7.41%\n"
     ]
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)\n",
    "scores = classifier.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0  0  0  0  0  0]\n",
      " [52  0  0  0  0  0  0  0]\n",
      " [55  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0]\n",
      " [59  0  0  0  0  0  0  0]\n",
      " [59  0  0  0  0  0  0  0]\n",
      " [63  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
