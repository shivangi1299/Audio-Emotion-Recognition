{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../extractedData/details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[list(df.columns)[3:]] #to get the relevant columnns (tonnetz, MFCC, chroma etc.)\n",
    "#X = preprocessing.normalize(X) #to normalize the data\n",
    "y = df['emotion']\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "#X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "#to split data into training and testing => 75:25 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.19      0.18      0.19        22\n",
      "         2.0       0.48      0.48      0.48        56\n",
      "         3.0       0.26      0.29      0.27        42\n",
      "         4.0       0.26      0.32      0.29        50\n",
      "         5.0       0.57      0.62      0.60        50\n",
      "         6.0       0.33      0.36      0.34        39\n",
      "         7.0       0.13      0.11      0.12        46\n",
      "         8.0       0.55      0.40      0.46        55\n",
      "\n",
      "   micro avg       0.36      0.36      0.36       360\n",
      "   macro avg       0.35      0.34      0.34       360\n",
      "weighted avg       0.37      0.36      0.36       360\n",
      "\n",
      "Confusion matrix for decision trees:\n",
      "[[ 4  8  0  5  1  1  3  0]\n",
      " [ 6 27  1 15  0  2  5  0]\n",
      " [ 4  1 12  3  5  9  5  3]\n",
      " [ 2 11  6 16  0  7  6  2]\n",
      " [ 1  1  7  2 31  4  2  2]\n",
      " [ 1  3  8  4  4 14  5  0]\n",
      " [ 3  2  7 11  4  3  5 11]\n",
      " [ 0  3  6  5  9  3  7 22]]\n",
      "Accuracy: 0.28 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "#decision tree classifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "predictions = dtree.predict(X_test)\n",
    "accuracy=metrics.accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"Confusion matrix for decision trees:\")\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "scores1 = cross_val_score(dtree, X, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.29      0.27      0.28        22\n",
      "         2.0       0.50      0.66      0.57        56\n",
      "         3.0       0.26      0.40      0.32        42\n",
      "         4.0       0.28      0.22      0.25        50\n",
      "         5.0       0.54      0.58      0.56        50\n",
      "         6.0       0.43      0.38      0.41        39\n",
      "         7.0       0.29      0.20      0.23        46\n",
      "         8.0       0.51      0.38      0.44        55\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       360\n",
      "   macro avg       0.39      0.39      0.38       360\n",
      "weighted avg       0.40      0.40      0.40       360\n",
      "\n",
      "Confusion matrix for random forest:\n",
      "[[ 6  9  1  3  0  0  2  1]\n",
      " [ 5 37  0 10  0  0  2  2]\n",
      " [ 0  3 17  2  8  5  4  3]\n",
      " [ 4 15  6 11  0  7  4  3]\n",
      " [ 0  1  9  1 29  1  3  6]\n",
      " [ 2  1 10  6  3 15  2  0]\n",
      " [ 2  5 12  3  6  4  9  5]\n",
      " [ 2  3 10  3  8  3  5 21]]\n",
      "Accuracy: 0.32 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "#random forest classifier\n",
    "rfor = RandomForestClassifier(n_estimators=10, random_state = 45)\n",
    "rfor = rfor.fit(X_train, y_train)\n",
    "predictions2 = rfor.predict(X_test)\n",
    "print(classification_report(y_test,predictions2))\n",
    "accuracy=metrics.accuracy_score(y_test, predictions2)\n",
    "print(\"Confusion matrix for random forest:\")\n",
    "print(confusion_matrix(y_test,predictions2))\n",
    "scores2 = cross_val_score(rfor, X, y, cv=5)      \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.26      0.27      0.27        22\n",
      "         2.0       0.44      0.59      0.50        56\n",
      "         3.0       0.25      0.36      0.30        42\n",
      "         4.0       0.38      0.34      0.36        50\n",
      "         5.0       0.49      0.52      0.50        50\n",
      "         6.0       0.53      0.59      0.56        39\n",
      "         7.0       0.19      0.13      0.15        46\n",
      "         8.0       0.60      0.33      0.42        55\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       360\n",
      "   macro avg       0.39      0.39      0.38       360\n",
      "weighted avg       0.41      0.40      0.39       360\n",
      "\n",
      "Confusion matrix for Extra Trees Classifier:\n",
      "[[ 6  9  1  3  0  0  2  1]\n",
      " [ 5 37  0 10  0  0  2  2]\n",
      " [ 0  3 17  2  8  5  4  3]\n",
      " [ 4 15  6 11  0  7  4  3]\n",
      " [ 0  1  9  1 29  1  3  6]\n",
      " [ 2  1 10  6  3 15  2  0]\n",
      " [ 2  5 12  3  6  4  9  5]\n",
      " [ 2  3 10  3  8  3  5 21]]\n",
      "\n",
      "Accuracy for Extra Trees: 0.33 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#Extra trees classifier\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=45)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions6 = clf.predict(X_test)\n",
    "accuracy=metrics.accuracy_score(y_test, predictions6)\n",
    "print(classification_report(y_test,predictions6))\n",
    "print(\"Confusion matrix for Extra Trees Classifier:\")\n",
    "print(confusion_matrix(y_test,predictions2))\n",
    "scores3 = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"\\nAccuracy for Extra Trees: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.08      0.09      0.09        22\n",
      "         2.0       0.40      0.71      0.52        56\n",
      "         3.0       0.23      0.07      0.11        42\n",
      "         4.0       0.33      0.08      0.13        50\n",
      "         5.0       0.32      0.78      0.45        50\n",
      "         6.0       0.24      0.10      0.14        39\n",
      "         7.0       0.24      0.24      0.24        46\n",
      "         8.0       0.26      0.13      0.17        55\n",
      "\n",
      "   micro avg       0.31      0.31      0.31       360\n",
      "   macro avg       0.26      0.28      0.23       360\n",
      "weighted avg       0.28      0.31      0.25       360\n",
      "\n",
      "Confusion matrix for AdaBoost Classifier:\n",
      "[[ 6  9  1  3  0  0  2  1]\n",
      " [ 5 37  0 10  0  0  2  2]\n",
      " [ 0  3 17  2  8  5  4  3]\n",
      " [ 4 15  6 11  0  7  4  3]\n",
      " [ 0  1  9  1 29  1  3  6]\n",
      " [ 2  1 10  6  3 15  2  0]\n",
      " [ 2  5 12  3  6  4  9  5]\n",
      " [ 2  3 10  3  8  3  5 21]]\n",
      "\n",
      "Accuracy for AdaBoost: 0.29 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost Classifier\n",
    "clf = AdaBoostClassifier(n_estimators=20)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions7 = clf.predict(X_test)\n",
    "accuracy=metrics.accuracy_score(y_test, predictions7)\n",
    "print(classification_report(y_test,predictions7))\n",
    "print(\"Confusion matrix for AdaBoost Classifier:\")\n",
    "print(confusion_matrix(y_test,predictions2))\n",
    "scores4 = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"\\nAccuracy for AdaBoost: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "         2.0       0.44      0.79      0.57        56\n",
      "         3.0       0.27      0.38      0.31        42\n",
      "         4.0       0.58      0.28      0.38        50\n",
      "         5.0       0.61      0.54      0.57        50\n",
      "         6.0       0.40      0.31      0.35        39\n",
      "         7.0       0.26      0.30      0.28        46\n",
      "         8.0       0.47      0.36      0.41        55\n",
      "\n",
      "   micro avg       0.41      0.41      0.41       360\n",
      "   macro avg       0.38      0.37      0.36       360\n",
      "weighted avg       0.41      0.41      0.39       360\n",
      "\n",
      "Confusion matrix for gradient boosting:\n",
      "[[ 0 18  2  0  0  0  2  0]\n",
      " [ 2 44  2  5  0  1  2  0]\n",
      " [ 1  4 16  2  6  5  4  4]\n",
      " [ 1 16  8 14  0  2  6  3]\n",
      " [ 0  1  5  0 27  4  4  9]\n",
      " [ 1  3  8  1  8 12  4  2]\n",
      " [ 1  7 15  2  1  1 14  5]\n",
      " [ 1  6  4  0  2  5 17 20]]\n",
      "Accuracy: 0.32 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.05, max_features=2, max_depth=2, random_state=0)\n",
    "gb = gb_clf.fit(X_train, y_train)\n",
    "predictions5 = gb.predict(X_test)\n",
    "print(classification_report(y_test,predictions5))\n",
    "accuracy=metrics.accuracy_score(y_test, predictions5)\n",
    "print(\"Confusion matrix for gradient boosting:\")\n",
    "print(confusion_matrix(y_test,predictions5))\n",
    "scores5 = cross_val_score(gb_clf, X, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores5.mean(), scores5.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.19      0.23      0.21        22\n",
      "         2.0       0.53      0.73      0.61        56\n",
      "         3.0       0.24      0.33      0.28        42\n",
      "         4.0       0.33      0.22      0.27        50\n",
      "         5.0       0.51      0.52      0.51        50\n",
      "         6.0       0.34      0.36      0.35        39\n",
      "         7.0       0.29      0.26      0.28        46\n",
      "         8.0       0.55      0.31      0.40        55\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       360\n",
      "   macro avg       0.37      0.37      0.36       360\n",
      "weighted avg       0.40      0.39      0.38       360\n",
      "\n",
      "Confusion matrix for bagging with Decision Trees:\n",
      "[[ 5 10  0  4  0  0  3  0]\n",
      " [ 5 41  3  1  0  0  5  1]\n",
      " [ 3  3 14  4  9  4  2  3]\n",
      " [ 5 14  9 11  2  5  4  0]\n",
      " [ 1  1  9  0 26  6  2  5]\n",
      " [ 1  3 10  4  5 14  1  1]\n",
      " [ 4  4  6  7  2  7 12  4]\n",
      " [ 2  2  8  2  7  5 12 17]]\n",
      "\n",
      "Accuracy after bagging with Decision Trees: 0.30 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#Bagging using Decision Trees\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.3, max_features=0.7) #more dependent on features than samples\n",
    "bagging.fit(X_train, y_train)\n",
    "predictions3 = bagging.predict(X_test)\n",
    "accuracy=metrics.accuracy_score(y_test, predictions3)\n",
    "print(classification_report(y_test,predictions3))\n",
    "print(\"Confusion matrix for bagging with Decision Trees:\")\n",
    "print(confusion_matrix(y_test,predictions3))\n",
    "scores6 = cross_val_score(bagging, X, y, cv=10)\n",
    "print(\"\\nAccuracy after bagging with Decision Trees: %0.2f (+/- %0.2f)\" % (scores6.mean(), scores6.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.28      0.23      0.25        22\n",
      "         2.0       0.56      0.71      0.63        56\n",
      "         3.0       0.37      0.45      0.40        42\n",
      "         4.0       0.43      0.30      0.35        50\n",
      "         5.0       0.58      0.60      0.59        50\n",
      "         6.0       0.49      0.46      0.47        39\n",
      "         7.0       0.30      0.28      0.29        46\n",
      "         8.0       0.49      0.45      0.47        55\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       360\n",
      "   macro avg       0.44      0.44      0.43       360\n",
      "weighted avg       0.45      0.46      0.45       360\n",
      "\n",
      "Confusion matrix for decision trees:\n",
      "[[ 5 10  1  3  0  0  3  0]\n",
      " [ 3 40  1  8  0  1  3  0]\n",
      " [ 2  3 19  0  9  2  4  3]\n",
      " [ 1 13  7 15  1  7  3  3]\n",
      " [ 1  1  4  0 30  3  1 10]\n",
      " [ 0  1  5  6  4 18  3  2]\n",
      " [ 4  4  8  2  4  3 13  8]\n",
      " [ 2  0  7  1  4  3 13 25]]\n",
      "Accuracy: 0.35 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier()\n",
    "xg.fit(X_train, y_train)\n",
    "pickle.dump(xg, open(\"xgModelFinal.pickle.dat\", \"wb\"))\n",
    "predictions4 = xg.predict(X_test)\n",
    "accuracy=metrics.accuracy_score(y_test, predictions4)\n",
    "print(classification_report(y_test,predictions4))\n",
    "print(\"Confusion matrix for decision trees:\")\n",
    "print(confusion_matrix(y_test,predictions4))\n",
    "scores7 = cross_val_score(xg, X, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores7.mean(), scores7.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AryaRajivChaloli\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "         2.0       0.18      1.00      0.31        56\n",
      "         3.0       0.00      0.00      0.00        42\n",
      "         4.0       0.00      0.00      0.00        50\n",
      "         5.0       0.86      0.48      0.62        50\n",
      "         6.0       0.67      0.21      0.31        39\n",
      "         7.0       0.00      0.00      0.00        46\n",
      "         8.0       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       360\n",
      "   macro avg       0.21      0.21      0.15       360\n",
      "weighted avg       0.22      0.24      0.17       360\n",
      "\n",
      "Confusion matrix for SVM:\n",
      "[[ 0 22  0  0  0  0  0  0]\n",
      " [ 0 56  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  1  4  0]\n",
      " [ 0 50  0  0  0  0  0  0]\n",
      " [ 0 21  0  0 24  2  2  1]\n",
      " [ 0 21  0  2  4  8  4  0]\n",
      " [ 0 46  0  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  1  2  0]]\n",
      "Accuracy: 0.19 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(X, y)\n",
    "predictions8 = clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions8))\n",
    "accuracy=metrics.accuracy_score(y_test, predictions8)\n",
    "print(\"Confusion matrix for SVM:\")\n",
    "print(confusion_matrix(y_test,predictions8))\n",
    "scores8 = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores8.mean(), scores8.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AryaRajivChaloli\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        22\n",
      "         2.0       0.33      0.91      0.49        56\n",
      "         3.0       0.27      0.17      0.21        42\n",
      "         4.0       0.12      0.18      0.15        50\n",
      "         5.0       0.54      0.58      0.56        50\n",
      "         6.0       0.21      0.08      0.11        39\n",
      "         7.0       0.10      0.02      0.04        46\n",
      "         8.0       0.28      0.15      0.19        55\n",
      "\n",
      "   micro avg       0.30      0.30      0.30       360\n",
      "   macro avg       0.23      0.26      0.22       360\n",
      "weighted avg       0.25      0.30      0.24       360\n",
      "\n",
      "Confusion matrix for ANN:\n",
      "[[ 0 18  0  4  0  0  0  0]\n",
      " [ 0 51  0  4  0  0  0  1]\n",
      " [ 0 11  7  7  6  6  1  4]\n",
      " [ 0 34  1  9  0  0  2  4]\n",
      " [ 0  1  5  6 29  0  2  7]\n",
      " [ 0  8  5  3 16  3  1  3]\n",
      " [ 0 19  5 18  0  1  1  2]\n",
      " [ 0 11  3 23  3  4  3  8]]\n",
      "Accuracy: 0.27 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X, y)\n",
    "predictions8 = clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions8))\n",
    "accuracy=metrics.accuracy_score(y_test, predictions8)\n",
    "print(\"Confusion matrix for ANN:\")\n",
    "print(confusion_matrix(y_test,predictions8))\n",
    "scores8 = cross_val_score(clf, X, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores8.mean(), scores8.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
